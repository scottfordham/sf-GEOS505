{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bf2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pyproj import CRS\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "\n",
    "PROJ_NAME_MAP = {\n",
    "    'NAD83 / Conus Albers': ('aea', 'NAD83'),\n",
    "    'Albers Conical Equal Area': ('aea', None),\n",
    "    'Lambert Conformal Conic': ('lcc', None),\n",
    "    'Transverse Mercator': ('tmerc', None),\n",
    "    # extend as you encounter new projection names\n",
    "}\n",
    "gs_3dep_url = 'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/ID_FEMAHQ_2018_D18/ID_FEMAHQ_2018/'\n",
    "gs_3dep_meta_url = 'metadata/'\n",
    "gs_3dep_browse_url = 'browse/'\n",
    "gs_3dep_las_url = 'LAZ/'\n",
    "\n",
    "output_geojson_geo = 'ID_FEMAHQ_2018_las_tiles.geojson'\n",
    "output_geojson_proj = 'ID_FEMAHQ_2018_las_tiles_alb.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43139da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(gs_3dep_url):\n",
    "    \n",
    "    reqs = requests.get(gs_3dep_url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "    xml_links = []\n",
    "    for link_tag in soup.find_all('a', href=True): # Find all <a> tags with an href attribute\n",
    "        href = link_tag.get('href')\n",
    "        if href and href.lower().endswith('.xml'): # Check if the link ends with '.xml'\n",
    "            # You may need to construct absolute URLs if hrefs are relative\n",
    "            if href.startswith('http') or href.startswith('https'):\n",
    "                xml_links.append(href)\n",
    "            else:\n",
    "                # Handle relative URLs (basic example, might need more robust handling for complex cases)\n",
    "                from urllib.parse import urljoin\n",
    "                absolute_url = urljoin(gs_3dep_url, href)\n",
    "                xml_links.append(absolute_url)\n",
    "                \n",
    "    return xml_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955872ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tile_xml(url: str) -> dict:\n",
    "    resp = requests.get(url, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.content, 'xml')\n",
    "\n",
    "    bounds_xml = soup.find('spdom').find('bounding')\n",
    "    bbox = {\n",
    "        'west': float(bounds_xml.find('westbc').text),\n",
    "        'east': float(bounds_xml.find('eastbc').text),\n",
    "        'north': float(bounds_xml.find('northbc').text),\n",
    "        'south': float(bounds_xml.find('southbc').text),\n",
    "    }\n",
    "\n",
    "    mapproj = soup.find('horizsys').find('planar').find('mapproj')\n",
    "    proj_name = mapproj.find('mapprojn').text.strip()\n",
    "\n",
    "    # prefer EPSG or WKT if present\n",
    "    epsg_tag = soup.find('refsysid')\n",
    "    if epsg_tag and epsg_tag.find('code'):\n",
    "        crs = CRS.from_epsg(int(epsg_tag.find('code').text))\n",
    "    elif mapproj.find('planarco'):\n",
    "        crs = CRS.from_wkt(mapproj.find('planarco').text)\n",
    "    else:\n",
    "        proj_alias, datum = PROJ_NAME_MAP.get(proj_name, (None, None))\n",
    "        params = {}\n",
    "        if proj_alias == 'aea' and mapproj.albers:\n",
    "            stdpars = mapproj.albers.find_all('stdparll')\n",
    "            params = {\n",
    "                'proj': 'aea',\n",
    "                'lat_1': float(stdpars[0].text),\n",
    "                'lat_2': float(stdpars[1].text),\n",
    "                'lat_0': float(mapproj.albers.find('latprjo').text),\n",
    "                'lon_0': float(mapproj.albers.find('longcm').text),\n",
    "                'x_0': float(mapproj.albers.find('feast').text),\n",
    "                'y_0': float(mapproj.albers.find('fnorth').text),\n",
    "                'datum': datum or 'WGS84',\n",
    "                'units': 'm',\n",
    "            }\n",
    "        # add elif blocks for other projections (lcc, tmerc, utm...) using their tags\n",
    "        if params:\n",
    "            crs = CRS.from_dict(params)\n",
    "        else:\n",
    "            crs = CRS.from_user_input(proj_name)  # final fallback\n",
    "\n",
    "    return {'bbox': bbox, 'crs': crs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a5530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for an entire project\n",
    "project_xmls = parse_html(gs_3dep_url+gs_3dep_meta_url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_meta = parse_tile_xml(project_xmls[0])  # same CRS for all tiles in this project\n",
    "project_crs = project_meta['crs']\n",
    "\n",
    "records = []\n",
    "for i, url in enumerate(project_xmls):\n",
    "    meta = parse_tile_xml(url)\n",
    "    records.append(\n",
    "        {\n",
    "            'tile_id': url[-14:-4],\n",
    "            'xml_url': url,\n",
    "            'browse_url': url.replace(gs_3dep_meta_url,gs_3dep_browse_url)[0:-4]+'.jpg',\n",
    "            'laz_url': url.replace(gs_3dep_meta_url,gs_3dep_las_url)[0:-4]+'.laz',\n",
    "            'geometry': box(meta['bbox']['west'], meta['bbox']['south'],\n",
    "                            meta['bbox']['east'], meta['bbox']['north']),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f'\\rCompleted {i/len(project_xmls):.2%} of XML files...')\n",
    "\n",
    "tiles_gdf_geo = gpd.GeoDataFrame(records, crs='EPSG:4326')\n",
    "tiles_gdf_proj = tiles_gdf_geo.to_crs(project_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ea065",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_gdf_geo.to_file(output_geojson_geo)\n",
    "tiles_gdf_proj.to_file(output_geojson_proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af273f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = project_xmls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c0ed5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/ID_FEMAHQ_2018_D18/ID_FEMAHQ_2018/metadata/USGS_LPC_ID_FEMAHQ_2018_D18_w1488n2451.xml'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6b1ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/ID_FEMAHQ_2018_D18/ID_FEMAHQ_2018/browse/USGS_LPC_ID_FEMAHQ_2018_D18_w1488n2451.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.replace(gs_3dep_meta_url,gs_3dep_browse_url)[0:-4]+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88a321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
